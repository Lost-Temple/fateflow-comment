# component provider, relative path to get_fate_python_directory
default_component_provider_path: federatedml

# resource
# 总资源超配百分比
total_cores_overweight_percent: 1  # 1 means no overweight，在资源管理中计算总核心数时，cores = cores_per_node * nodes * total_cores_overweight_percent
total_memory_overweight_percent: 1  # 1 means no overweight
# 默认的每个作业的任务并行度，可以在提交作业配置时使用job_parameters:task_parallelism配置自定义值
task_parallelism: 1
# 默认的每个作业中每个任务使用的CPU核数，可以在提交作业配置时使用job_parameters:task_cores配置自定义值
# 如果在提交作业配置中没有指定，那就把下面配置的task_cores的值赋给request_task_cores
# 然后通过数据库表t_engine_registry表中的数据得到task_nodes（表示多少个计算节点）
# 然后通过然后通过计算公式task_cores_per_node = max(1, request_task_cores/task_nodes)得到task_cores_per_node
# 后续computing_partitions 可以根据 task_cores_per_node * task_nodes 得到。这个computing_partitions的值就是后续
# 计算引擎分布式计算的并行数
task_cores: 4
# 暂时不支持内存资源的调度，该配置不生效
task_memory: 0  # mb
# 一个作业最大允许申请的CPU核数占总资源数量的比例，如总资源为10，此值为0.5，则表示一个作业最多允许申请5个CPU，也即task_cores * task_parallelism <= 10 * 0.5
max_cores_percent_per_job: 1  # 1 means total

# scheduling
job_timeout: 259200 # s
remote_request_timeout: 30000  # ms
federated_command_trys: 3
end_status_job_scheduling_time_limit: 300000 # ms
end_status_job_scheduling_updates: 1
auto_retries: 0
auto_retry_delay: 1  #seconds
# It can also be specified in the job configuration using the federated_status_collect_type parameter
federated_status_collect_type: PUSH
detect_connect_max_retry_count: 3
detect_connect_long_retry_count: 2

task_process_classpath: true

# upload
upload_block_max_bytes: 104857600 # bytes

#component output
output_data_summary_count_limit: 100

# gpu
task_world_size: 2
resource_waiting_timeout: 21600 # s